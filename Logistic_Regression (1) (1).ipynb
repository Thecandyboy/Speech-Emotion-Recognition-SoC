{"cells":[{"cell_type":"markdown","metadata":{"id":"aTAky_OS1w0P"},"source":["# Logistic Regression\n","\n","Logistic regression is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome; something that can take two values such as true/false, yes/no, and so on.\n","\n","In this week you will be doing logistic regression on breast cancer dataset using sklearn library. Feel free to create any new functions required."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"E56ck0_P2NR9","executionInfo":{"status":"ok","timestamp":1719421214356,"user_tz":-330,"elapsed":2333,"user":{"displayName":"Adarsh JD","userId":"13555311760430374565"}}},"outputs":[],"source":["#importinf libraries\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn import datasets\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"qojSAol72cmH"},"source":["Prepare Data"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"_uUSV8Xk2ePh","executionInfo":{"status":"ok","timestamp":1719421219069,"user_tz":-330,"elapsed":553,"user":{"displayName":"Adarsh JD","userId":"13555311760430374565"}}},"outputs":[],"source":["breast_cancer = datasets.load_breast_cancer()\n","X, y = breast_cancer.data, breast_cancer.target"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"N6jcbk5g29XW","executionInfo":{"status":"ok","timestamp":1719421222736,"user_tz":-330,"elapsed":670,"user":{"displayName":"Adarsh JD","userId":"13555311760430374565"}}},"outputs":[],"source":["#spliting data for training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"R4ldHUJs3d2V"},"source":["Binary cross entropy loss"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QkXgo04D3dGW","executionInfo":{"status":"ok","timestamp":1719421226231,"user_tz":-330,"elapsed":516,"user":{"displayName":"Adarsh JD","userId":"13555311760430374565"}}},"outputs":[],"source":["def BCELoss(y,y_pred):\n","  ep = 1e-15\n","  y_pred = np.clip(y_pred, ep, 1 - ep)\n","  return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))"]},{"cell_type":"markdown","metadata":{"id":"OIuuOJcJ3sti"},"source":["Implement Logistic Regression here :)\n","\n","Print the accuracy and cross entropy loss"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gBJ6H_ss3yUr","executionInfo":{"status":"ok","timestamp":1719421228480,"user_tz":-330,"elapsed":6,"user":{"displayName":"Adarsh JD","userId":"13555311760430374565"}}},"outputs":[],"source":["def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","\n","class LogisticRegression:\n","  def __init__(self, lr=0.01, iters=1000): #lr (learning rate) & iters (iterations) could be anything of your choice\n","    self.lr = lr\n","    self.iters = iters\n","    self.weights = None\n","    self.bias = None\n","\n","  def fit(self, X, y):\n","    n_samples, n_features = X.shape\n","    self.weights = np.zeros(n_features)\n","    self.bias = 0\n","\n","    for _ in range(self.iters):\n","      linear_model = np.dot(X, self.weights) + self.bias\n","      y_pred = sigmoid(linear_model)\n","\n","      # Gradient Descent\n","      dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n","      db = (1 / n_samples) * np.sum(y_pred - y)\n","\n","      self.weights -= self.lr * dw\n","      self.bias -= self.lr * db\n","\n","  def predict(self, X):\n","    linear_model = np.dot(X, self.weights) + self.bias\n","    y_pred = sigmoid(linear_model)\n","    y_pred_cls = [1 if i > 0.5 else 0 for i in y_pred]\n","    return np.array(y_pred_cls)\n","\n","\n"]},{"cell_type":"code","source":["model = LogisticRegression(lr=0.01, iters=1000)\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","loss = BCELoss(y_test, sigmoid(np.dot(X_test, model.weights) + model.bias))\n","\n","print(f'Accuracy: {accuracy}')\n","print(f'Binary Cross-Entropy Loss: {loss}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLjKSFpT4Z97","executionInfo":{"status":"ok","timestamp":1719421233588,"user_tz":-330,"elapsed":1189,"user":{"displayName":"Adarsh JD","userId":"13555311760430374565"}},"outputId":"613f1e33-932d-49d4-e8e2-247f7cccc819"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9385964912280702\n","Binary Cross-Entropy Loss: 0.16113495819476906\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}